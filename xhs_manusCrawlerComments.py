"""
è¯´æ˜ï¼š
ã€å°çº¢ä¹¦è¯„è®ºæ•°æ®æŠ“å–è„šæœ¬ã€‘
åœ¨è¡¨æ ¼ä¸­å¡«å…¥è¦æŠ“å–çš„ç¬”è®°é“¾æ¥ï¼Œè„šæœ¬ä¼šæ‰“å¼€æ¯ä¸ªå°çº¢ä¹¦é“¾æ¥ï¼Œæ‰‹åŠ¨å¿«é€Ÿæ»šåŠ¨æ‰€æœ‰è¯„è®ºï¼Œè‡ªåŠ¨æŠ“å–æ‰€æœ‰è¯„è®ºæ•°æ®å¹¶ä¿å­˜åˆ°CSVå’ŒJSONæ–‡ä»¶ä¸­ã€‚
ç”¨æœ€ç®€å•çš„ä»£ç ï¼Œå®ç°æœ€å¼ºä¸å°ç¦çš„åŠŸèƒ½ã€‚

åŠŸèƒ½ï¼š
1. å¯åŠ¨Chromeæµè§ˆå™¨ï¼Œè¿›å…¥å°çº¢ä¹¦é¦–é¡µï¼Œç­‰å¾…ç”¨æˆ·æ‰«ç ç™»å½•ï¼ˆç™»å½•ä¿¡æ¯ä¼šä¿å­˜ï¼‰
2. ä»Excelæ–‡ä»¶æˆ–å˜é‡åˆ—è¡¨è¯»å–å¤šä¸ªè§†é¢‘é“¾æ¥
3. åœ¨æ–°æ ‡ç­¾é¡µæ‰“å¼€æ¯ä¸ªé“¾æ¥
4. ç›‘å¬è¯„è®ºAPIè¯·æ±‚ï¼Œè‡ªåŠ¨è§£æå“åº”ä½“æ•°æ®
5. ä¿å­˜æ•°æ®åˆ°CSVå’ŒJSONæ–‡ä»¶ï¼ˆæŒ‰note_idåˆ†åˆ«ä¿å­˜ï¼ŒåŒæ—¶ä¿å­˜æ€»æ–‡ä»¶ï¼‰

ä½¿ç”¨æ–¹æ³•ï¼š
1. å®‰è£…ä¾èµ–ï¼špip install playwright openpyxl rich
2. å®‰è£…æµè§ˆå™¨ï¼šplaywright install chromium
3. åœ¨URL_LISTå˜é‡ä¸­å¡«å…¥é“¾æ¥ï¼Œæˆ–å‡†å¤‡xiaohongshuVidioUrlTemplate.xlsxæ–‡ä»¶
4. è¿è¡Œè„šæœ¬ï¼špython xhs_manusCrawlerComments.py
5. åœ¨æµè§ˆå™¨ä¸­æ‰«ç ç™»å½•ï¼ˆé¦–æ¬¡è¿è¡Œï¼‰
6. è„šæœ¬ä¼šè‡ªåŠ¨æ‰“å¼€æ‰€æœ‰é“¾æ¥å¹¶ç›‘å¬è¯„è®ºæ•°æ®
7. å½“ç”¨æˆ·åœ¨æµè§ˆå™¨ä¸­ç¿»é¡µæŸ¥çœ‹è¯„è®ºæ—¶ï¼Œæ•°æ®ä¼šè‡ªåŠ¨ä¿å­˜
8. æŒ‰Ctrl+Cåœæ­¢è„šæœ¬

è¾“å‡ºæ–‡ä»¶ï¼š
- æ¯ä¸ªnote_idä¼šç”Ÿæˆï¼š1_[æ ‡é¢˜]_[note_id].json å’Œ 1_[æ ‡é¢˜]_[note_id].csv
- æ‰€æœ‰æ•°æ®æ±‡æ€»ï¼šAll CommentData.json å’Œ All CommentData.csv

æ³¨æ„ï¼š
- é¦–æ¬¡è¿è¡Œéœ€è¦ç™»å½•ï¼Œç™»å½•ä¿¡æ¯ä¼šä¿å­˜ï¼Œä¸‹æ¬¡è¿è¡Œæ— éœ€é‡æ–°ç™»å½•
- è„šæœ¬ä¼šæŒç»­è¿è¡Œï¼Œç›‘å¬è¯„è®ºæ•°æ®ï¼Œç›´åˆ°ç”¨æˆ·æ‰‹åŠ¨åœæ­¢
- éœ€è¦ç¡®ä¿Excelæ–‡ä»¶æ ¼å¼æ­£ç¡®ï¼ˆç¬¬ä¸€è¡Œä¸ºæ ‡é¢˜ï¼Œä»ç¬¬äºŒè¡Œå¼€å§‹æ˜¯URLï¼‰

å¾…åŠï¼š
1ã€åšå„ç§å¹³å°è¯„è®ºæ•°æ®æŠ“å–çš„é€‚é…æ¨¡æ¿ï¼Œä»£ç ä¸­é…ç½®å¹³å°çš„è¯„è®ºæ¥å£urlã€å“åº”ä½“ã€post id è¿™3é¡¹æ•°æ®å³å¯é€‚é…ç›¸åº”çš„å¹³å°ã€‚å°±ä½ è·‘ä»£ç æŠ“å–ä¸åŒå¹³å°çš„è¯„è®ºæ•°æ®äº†ï¼Œè€Œä¸”è¿™ç§æ–¹å¼æ°¸è¿œä¸ä¼šè¢«å¹³å°è®¤ä¸ºæ˜¯è‡ªåŠ¨åŒ–çˆ¬æ•°æ®ã€‚
"""

import asyncio
import csv
import json
import re
import os
from pathlib import Path
from playwright.async_api import async_playwright, BrowserContext, Page, Response
from typing import Dict, List, Set
import openpyxl
from rich.console import Console
from rich.live import Live
from rich.table import Table
from rich.panel import Panel
from rich.progress import Progress, SpinnerColumn, BarColumn, TextColumn, TimeElapsedColumn
from rich.layout import Layout
from rich.text import Text
from rich import box


# ========== é…ç½®åŒºåŸŸï¼šå¯ä»¥åœ¨è¿™é‡Œå¡«å…¥è¦çˆ¬å–çš„å°çº¢ä¹¦ç¬”è®°é“¾æ¥ ==========
URL_LIST = [
    # 'http://xhslink.com/o/315a7XzU2Ho',
    # 'https://www.xiaohongshu.com/user/profile/59f8c90c11be103e7447cb0d?xsec_token=AB077S8P4Fy8-0QLGd0-QTJ0trZXaqrP9Q6WmBrS1Gvts=&xsec_source=pc_note',
]
# ================================================================

# Excelæ–‡ä»¶è·¯å¾„ï¼ˆç›¸å¯¹äºè„šæœ¬æ–‡ä»¶æ‰€åœ¨ç›®å½•ï¼‰
SCRIPT_DIR = Path(__file__).parent.absolute()
EXCEL_FILE = str(SCRIPT_DIR / 'xiaohongshuVidioUrlTemplate.xlsx')

# æ•°æ®æ–‡ä»¶ä¿å­˜ç›®å½•ï¼ˆä¸è„šæœ¬åŒçº§ï¼‰
DATA_FILE_DIR = SCRIPT_DIR / 'DataFile'

# è¯„è®ºAPI URLæ¨¡å¼
COMMENT_API_PATTERN = 'https://edith.xiaohongshu.com/api/sns/web/v2/comment/page?note_id='

# å­˜å‚¨æ‰€æœ‰è¯„è®ºæ•°æ®çš„å­—å…¸ï¼Œkeyä¸ºnote_idï¼Œvalueä¸ºåµŒå¥—ç»“æ„çš„è¯„è®ºåˆ—è¡¨ï¼ˆä¸€çº§è¯„è®ºåŒ…å«sub_commentsï¼‰
all_comments_data: Dict[str, List[Dict]] = {}

# å­˜å‚¨æ‰å¹³åŒ–çš„è¯„è®ºæ•°æ®ï¼ˆç”¨äºCSVå¯¼å‡ºï¼‰ï¼Œkeyä¸ºnote_id
all_comments_flat: Dict[str, List[Dict]] = {}

# å­˜å‚¨å·²å¤„ç†çš„note_idï¼Œé¿å…é‡å¤å¤„ç†
processed_note_ids: Set[str] = set()

# å­˜å‚¨note_idå’Œé¡µé¢æ ‡é¢˜çš„æ˜ å°„å…³ç³»
note_id_to_title: Dict[str, str] = {}

# å­˜å‚¨note_idå’Œé¡µé¢çš„æ˜ å°„å…³ç³»
note_id_to_page: Dict[str, Page] = {}

# å­˜å‚¨note_idå’Œæ–‡ä»¶åºå·çš„æ˜ å°„å…³ç³»
note_id_to_index: Dict[str, int] = {}

# å­˜å‚¨note_idå’Œæ€»è¯„è®ºæ•°çš„æ˜ å°„å…³ç³»
note_id_to_total_count: Dict[str, int] = {}

# Rich æ§åˆ¶å°å¯¹è±¡
console = Console()

# å…¨å±€ Live å¯¹è±¡ï¼ˆç”¨äºå®æ—¶æ›´æ–°æ˜¾ç¤ºï¼‰
live_display = None


def get_user_data_dir():
    """è·å–æŒä¹…åŒ–ç”¨æˆ·æ•°æ®ç›®å½•ï¼ˆä¿å­˜ç™»å½•çŠ¶æ€ï¼‰"""
    home_dir = Path.home()
    data_dir = home_dir / '.playwright-xhs-crawler'
    data_dir.mkdir(exist_ok=True)
    return str(data_dir)


def ensure_data_file_dir():
    """ç¡®ä¿æ•°æ®æ–‡ä»¶ç›®å½•å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»º"""
    DATA_FILE_DIR.mkdir(exist_ok=True)
    return str(DATA_FILE_DIR)


def read_urls_from_excel(file_path: str) -> List[str]:
    """ä»Excelæ–‡ä»¶è¯»å–URLåˆ—è¡¨ï¼ˆå¿½ç•¥é¦–è¡Œæ ‡é¢˜ï¼‰"""
    urls = []
    try:
        if os.path.exists(file_path):
            wb = openpyxl.load_workbook(file_path)
            ws = wb.active
            
            # ä»ç¬¬äºŒè¡Œå¼€å§‹è¯»å–ï¼ˆå¿½ç•¥é¦–è¡Œæ ‡é¢˜ï¼‰
            for row in ws.iter_rows(min_row=2, values_only=True):
                for cell_value in row:
                    if cell_value and isinstance(cell_value, str):
                        url = str(cell_value).strip()
                        if url and (url.startswith('http://') or url.startswith('https://')):
                            urls.append(url)
            
            wb.close()
            console.print(f'[green]âœ“[/green] ä»Excelæ–‡ä»¶è¯»å–åˆ° [cyan]{len(urls)}[/cyan] ä¸ªURL')
        else:
            console.print(f'[yellow]âš [/yellow] Excelæ–‡ä»¶ä¸å­˜åœ¨: {file_path}')
    except Exception as e:
        console.print(f'[yellow]âš [/yellow] è¯»å–Excelæ–‡ä»¶å¤±è´¥: {str(e)}')
    
    return urls


def extract_note_id_from_url(url: str) -> str:
    """ä»URLä¸­æå–note_id"""
    # åŒ¹é… /explore/ åé¢çš„note_id
    match = re.search(r'/explore/([a-f0-9]+)', url)
    if match:
        return match.group(1)
    
    # åŒ¹é… note_id= å‚æ•°
    match = re.search(r'note_id=([a-f0-9]+)', url)
    if match:
        return match.group(1)
    
    return ''


def parse_comment_response(response_data: dict, note_id: str) -> tuple:
    """
    è§£æè¯„è®ºAPIå“åº”ä½“æ•°æ®
    è¿”å›ï¼š(åµŒå¥—ç»“æ„çš„è¯„è®ºåˆ—è¡¨, æ‰å¹³åŒ–çš„è¯„è®ºåˆ—è¡¨)
    """
    nested_comments = []
    flat_comments = []
    
    try:
        if not response_data.get('success') or response_data.get('code') != 0:
            return nested_comments, flat_comments
        
        data = response_data.get('data', {})
        comments_list = data.get('comments', [])
        
        for comment in comments_list:
            # è§£æä¸€çº§è¯„è®ºï¼ˆåµŒå¥—ç»“æ„ï¼Œç”¨äºJSONï¼‰
            comment_data = {
                'content': comment.get('content', ''),
                'like_count': comment.get('like_count', '0'),
                'ip_location': comment.get('ip_location', ''),
                'nickname': comment.get('user_info', {}).get('nickname', ''),
                'comment_id': comment.get('id', ''),
                'sub_comments': []  # äºŒçº§è¯„è®ºåµŒå¥—åœ¨è¿™é‡Œ
            }
            
            # æ‰å¹³åŒ–çš„ä¸€çº§è¯„è®ºï¼ˆç”¨äºCSVï¼‰
            flat_comment = {
                'content': comment.get('content', ''),
                'like_count': comment.get('like_count', '0'),
                'ip_location': comment.get('ip_location', ''),
                'nickname': comment.get('user_info', {}).get('nickname', ''),
                'note_id': note_id,
                'comment_id': comment.get('id', ''),
                'parent_comment_id': '',
                'is_sub_comment': False
            }
            flat_comments.append(flat_comment)
            
            # è§£æäºŒçº§è¯„è®ºï¼ˆsub_commentsï¼‰
            sub_comments = comment.get('sub_comments', [])
            for sub_comment in sub_comments:
                # åµŒå¥—ç»“æ„çš„äºŒçº§è¯„è®ºï¼ˆç”¨äºJSONï¼‰
                sub_comment_data = {
                    'content': sub_comment.get('content', ''),
                    'like_count': sub_comment.get('like_count', '0'),
                    'ip_location': sub_comment.get('ip_location', ''),
                    'nickname': sub_comment.get('user_info', {}).get('nickname', ''),
                    'comment_id': sub_comment.get('id', '')
                }
                comment_data['sub_comments'].append(sub_comment_data)
                
                # æ‰å¹³åŒ–çš„äºŒçº§è¯„è®ºï¼ˆç”¨äºCSVï¼‰
                flat_sub_comment = {
                    'content': sub_comment.get('content', ''),
                    'like_count': sub_comment.get('like_count', '0'),
                    'ip_location': sub_comment.get('ip_location', ''),
                    'nickname': sub_comment.get('user_info', {}).get('nickname', ''),
                    'note_id': note_id,
                    'comment_id': sub_comment.get('id', ''),
                    'parent_comment_id': comment.get('id', ''),
                    'is_sub_comment': True
                }
                flat_comments.append(flat_sub_comment)
            
            nested_comments.append(comment_data)
        
        total_count = len(flat_comments)
        # ä½¿ç”¨ rich æ›´æ–°æ˜¾ç¤º
        update_display()
        
    except Exception as e:
        console.print(f'  [yellow]âš [/yellow] è§£æè¯„è®ºæ•°æ®å¤±è´¥: {str(e)}')
    
    return nested_comments, flat_comments


async def handle_comment_api_response(response: Response):
    """å¤„ç†è¯„è®ºAPIå“åº”ï¼Œè§£æå“åº”ä½“æ•°æ®"""
    try:
        url = response.url
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯è¯„è®ºAPI
        if COMMENT_API_PATTERN not in url:
            return
        
        # ä»URLä¸­æå–note_id
        note_id_match = re.search(r'note_id=([a-f0-9]+)', url)
        if not note_id_match:
            return
        
        note_id = note_id_match.group(1)
        
        # è·å–å“åº”ä½“
        try:
            response_body = await response.json()
        except:
            # å¦‚æœå“åº”ä¸æ˜¯JSONï¼Œå¿½ç•¥
            return
        
        # è§£æè¯„è®ºæ•°æ®
        nested_comments, flat_comments = parse_comment_response(response_body, note_id)
        
        if nested_comments or flat_comments:
            # åˆå§‹åŒ–æ•°æ®ç»“æ„
            if note_id not in all_comments_data:
                all_comments_data[note_id] = []
            if note_id not in all_comments_flat:
                all_comments_flat[note_id] = []
            
            # æ”¶é›†å·²å­˜åœ¨çš„comment_idï¼ˆåµŒå¥—ç»“æ„ï¼‰
            existing_nested_ids = set()
            for c in all_comments_data[note_id]:
                existing_nested_ids.add(c['comment_id'])
                for sc in c.get('sub_comments', []):
                    existing_nested_ids.add(sc['comment_id'])
            
            # æ”¶é›†å·²å­˜åœ¨çš„comment_idï¼ˆæ‰å¹³ç»“æ„ï¼‰
            existing_flat_ids = {c['comment_id'] for c in all_comments_flat[note_id]}
            
            # è¿‡æ»¤æ–°è¯„è®º
            new_nested_comments = []
            new_flat_comments = []
            
            for nested_c in nested_comments:
                # æ£€æŸ¥ä¸€çº§è¯„è®ºæ˜¯å¦å·²å­˜åœ¨
                if nested_c['comment_id'] not in existing_nested_ids:
                    new_nested_comments.append(nested_c)
                    existing_nested_ids.add(nested_c['comment_id'])
                    
                    # æ‰¾åˆ°å¯¹åº”çš„ä¸€çº§è¯„è®ºæ‰å¹³æ•°æ®
                    flat_c = next((fc for fc in flat_comments if fc['comment_id'] == nested_c['comment_id'] and not fc.get('is_sub_comment', False)), None)
                    if flat_c and flat_c['comment_id'] not in existing_flat_ids:
                        new_flat_comments.append(flat_c)
                        existing_flat_ids.add(flat_c['comment_id'])
                    
                    # å¤„ç†äºŒçº§è¯„è®º
                    for sub_c in nested_c.get('sub_comments', []):
                        if sub_c['comment_id'] not in existing_nested_ids:
                            existing_nested_ids.add(sub_c['comment_id'])
                            # æ‰¾åˆ°å¯¹åº”çš„äºŒçº§è¯„è®ºæ‰å¹³æ•°æ®
                            flat_sub_c = next((fc for fc in flat_comments if fc['comment_id'] == sub_c['comment_id'] and fc.get('is_sub_comment', False)), None)
                            if flat_sub_c and flat_sub_c['comment_id'] not in existing_flat_ids:
                                new_flat_comments.append(flat_sub_c)
                                existing_flat_ids.add(flat_sub_c['comment_id'])
            
            if new_nested_comments:
                all_comments_data[note_id].extend(new_nested_comments)
                all_comments_flat[note_id].extend(new_flat_comments)
                # ä½¿ç”¨ rich æ›´æ–°æ˜¾ç¤º
                update_display()
                
                # å°è¯•è·å–é¡µé¢æ ‡é¢˜å’Œæ€»è¯„è®ºæ•°ï¼ˆå¦‚æœè¿˜æ²¡æœ‰ï¼‰
                if note_id not in note_id_to_title or note_id not in note_id_to_total_count:
                    # å°è¯•ä»å½“å‰å“åº”çš„é¡µé¢è·å–
                    try:
                        page = response.request.frame.page if hasattr(response.request, 'frame') else None
                        if page and not page.is_closed():
                            if note_id not in note_id_to_title:
                                title = await get_page_title(page)
                                if title:
                                    note_id_to_title[note_id] = title
                            if note_id not in note_id_to_total_count:
                                total_count = await get_total_comment_count(page)
                                if total_count > 0:
                                    note_id_to_total_count[note_id] = total_count
                        else:
                            # æŸ¥æ‰¾åŒ…å«è¯¥note_idçš„é¡µé¢
                            for pid, p in note_id_to_page.items():
                                if pid == note_id and not p.is_closed():
                                    if note_id not in note_id_to_title:
                                        title = await get_page_title(p)
                                        if title:
                                            note_id_to_title[note_id] = title
                                    if note_id not in note_id_to_total_count:
                                        total_count = await get_total_comment_count(p)
                                        if total_count > 0:
                                            note_id_to_total_count[note_id] = total_count
                                    break
                    except:
                        pass
                
                # ä¿å­˜æ•°æ®åˆ°æ–‡ä»¶
                await save_comments_to_file(note_id)
                await save_all_comments_to_file()
        
    except Exception as e:
        console.print(f'  [yellow]âš [/yellow] å¤„ç†è¯„è®ºAPIå“åº”å¤±è´¥: {str(e)}')


def create_status_panel() -> Panel:
    """åˆ›å»ºå®æ—¶çŠ¶æ€æ˜¾ç¤ºé¢æ¿"""
    # è®¡ç®—æ€»è¯„è®ºæ•°
    total_comments = sum(len(comments) for comments in all_comments_flat.values())
    total_note_ids = len(all_comments_data)
    
    # åˆ›å»ºç»Ÿè®¡ä¿¡æ¯è¡¨æ ¼
    stats_table = Table(show_header=False, box=None, padding=(0, 1))
    stats_table.add_row("ğŸ“Š æ€»è¯„è®ºæ•°:", f"[bold green]{total_comments}[/bold green]")
    stats_table.add_row("ğŸ“ å¤„ç†ç¬”è®°æ•°:", f"[bold cyan]{total_note_ids}[/bold cyan]")
    
    # åˆ›å»ºæ¯ä¸ªnote_idçš„è¯¦ç»†è¡¨æ ¼
    if all_comments_data:
        detail_table = Table(title="ğŸ“‹ å„ç¬”è®°è¯„è®ºç»Ÿè®¡", box=box.ROUNDED, show_header=True, header_style="bold magenta")
        detail_table.add_column("åºå·", style="cyan", width=6)
        detail_table.add_column("Note ID", style="yellow", width=20)
        detail_table.add_column("æ ‡é¢˜", style="green", width=30, overflow="ellipsis")
        detail_table.add_column("è¯„è®ºæ•°", style="bold blue", justify="right", width=12)
        detail_table.add_column("è¿›åº¦", style="bold", justify="right", width=15)
        
        for note_id, comments in sorted(all_comments_data.items(), 
                                       key=lambda x: note_id_to_index.get(x[0], 999)):
            index = note_id_to_index.get(note_id, 0)
            title = note_id_to_title.get(note_id, 'æœªçŸ¥æ ‡é¢˜')
            count = len(all_comments_flat.get(note_id, []))
            total_count = note_id_to_total_count.get(note_id, 0)
            
            # è®¡ç®—è¿›åº¦
            if total_count > 0:
                progress_percent = (count / total_count) * 100
                if progress_percent >= 100:
                    progress_text = f"[bold green]âœ“ 100%[/bold green]"
                else:
                    progress_text = f"[yellow]{progress_percent:.1f}%[/yellow]"
            else:
                progress_text = "[dim]ç­‰å¾…ä¸­...[/dim]"
            
            detail_table.add_row(
                str(index),
                note_id[:16] + "..." if len(note_id) > 16 else note_id,
                title[:28] + "..." if len(title) > 28 else title,
                f"{count}/{total_count}" if total_count > 0 else str(count),
                progress_text
            )
    else:
        detail_table = Table(title="ğŸ“‹ å„ç¬”è®°è¯„è®ºç»Ÿè®¡", box=box.ROUNDED)
        detail_table.add_column("çŠ¶æ€", style="yellow")
        detail_table.add_row("ç­‰å¾…æ•°æ®...")
    
    # åˆ›å»ºå¸ƒå±€
    layout = Layout()
    layout.split_column(
        Layout(Panel(stats_table, title="ğŸ“ˆ æ€»ä½“ç»Ÿè®¡", border_style="green"), size=5),
        Layout(detail_table)
    )
    
    return Panel(layout, title="[bold blue]å°çº¢ä¹¦è¯„è®ºæŠ“å–å®æ—¶ç›‘æ§[/bold blue]", border_style="blue")


def update_display():
    """æ›´æ–°å®æ—¶æ˜¾ç¤º"""
    global live_display
    if live_display:
        live_display.update(create_status_panel())


def sanitize_filename(filename: str) -> str:
    """æ¸…ç†æ–‡ä»¶åï¼Œç§»é™¤éæ³•å­—ç¬¦"""
    # ç§»é™¤æˆ–æ›¿æ¢éæ³•å­—ç¬¦
    illegal_chars = r'[<>:"/\\|?*]'
    filename = re.sub(illegal_chars, '_', filename)
    # é™åˆ¶æ–‡ä»¶åé•¿åº¦
    if len(filename) > 200:
        filename = filename[:200]
    return filename


async def get_page_title(page: Page) -> str:
    """è·å–é¡µé¢æ ‡é¢˜"""
    try:
        title = await page.title()
        return title.strip()
    except:
        return ''


async def get_total_comment_count(page: Page) -> int:
    """ä»é¡µé¢è·å–è¯„è®ºæ€»æ•°ï¼ˆé€šè¿‡class="total"å…ƒç´ ï¼‰"""
    try:
        # æŸ¥æ‰¾ class="total" çš„å…ƒç´ 
        total_element = await page.query_selector('.total')
        if total_element:
            text = await total_element.inner_text()
            # æå–æ•°å­—ï¼Œä¾‹å¦‚ "å…± 92 æ¡è¯„è®º" -> 92
            match = re.search(r'å…±\s*(\d+)\s*æ¡è¯„è®º', text)
            if match:
                return int(match.group(1))
    except Exception as e:
        # é™é»˜å¤„ç†é”™è¯¯
        pass
    return 0


async def save_comments_to_file(note_id: str):
    """ä¿å­˜æŒ‡å®šnote_idçš„è¯„è®ºæ•°æ®åˆ°æ–‡ä»¶"""
    if note_id not in all_comments_data or not all_comments_data[note_id]:
        return
    
    nested_comments = all_comments_data[note_id]
    flat_comments = all_comments_flat.get(note_id, [])
    
    # è·å–é¡µé¢æ ‡é¢˜
    page_title = note_id_to_title.get(note_id, '')
    
    # å¦‚æœè¿˜æ²¡æœ‰æ ‡é¢˜ï¼Œå°è¯•ä»é¡µé¢è·å–
    if not page_title and note_id in note_id_to_page:
        try:
            page = note_id_to_page[note_id]
            if not page.is_closed():
                page_title = await get_page_title(page)
                note_id_to_title[note_id] = page_title
        except:
            pass
    
    # å¦‚æœè¿˜æ˜¯æ²¡æœ‰æ ‡é¢˜ï¼Œä½¿ç”¨é»˜è®¤å€¼
    if not page_title:
        page_title = f'note_{note_id}'
    
    # è·å–æ–‡ä»¶åºå·
    file_index = note_id_to_index.get(note_id, 1)
    
    # ç”Ÿæˆæ–‡ä»¶åï¼šåºå·+æ ‡é¢˜:+title+note_idå€¼:+note_id
    safe_title = sanitize_filename(page_title)
    filename_base = f'{file_index} æ ‡é¢˜:{safe_title} note_idå€¼:{note_id}'
    
    # ç¡®ä¿æ•°æ®æ–‡ä»¶ç›®å½•å­˜åœ¨
    ensure_data_file_dir()
    
    # ä¿å­˜JSONï¼ˆåµŒå¥—ç»“æ„ï¼‰
    json_path = DATA_FILE_DIR / f'{filename_base}.json'
    with open(json_path, 'w', encoding='utf-8') as f:
        json.dump(nested_comments, f, ensure_ascii=False, indent=2)
    
    # ä¿å­˜CSVï¼ˆæ‰å¹³ç»“æ„ï¼ŒæŒ‰æŒ‡å®šåˆ—é¡ºåºï¼‰
    csv_path = DATA_FILE_DIR / f'{filename_base}.csv'
    if flat_comments:
        with open(csv_path, 'w', newline='', encoding='utf-8') as f:
            writer = csv.DictWriter(f, fieldnames=[
                'content', 'like_count', 'ip_location', 'nickname', 
                'note_id', 'comment_id', 'parent_comment_id', 'is_sub_comment'
            ])
            writer.writeheader()
            writer.writerows(flat_comments)
    
    # æ–‡ä»¶ä¿å­˜ä¿¡æ¯é€šè¿‡ rich æ˜¾ç¤ºï¼Œè¿™é‡Œä¸å•ç‹¬æ‰“å°
    update_display()


async def save_all_comments_to_file():
    """ä¿å­˜æ‰€æœ‰è¯„è®ºæ•°æ®åˆ°æ€»æ–‡ä»¶"""
    if not all_comments_data:
        return
    
    # åˆå¹¶æ‰€æœ‰åµŒå¥—è¯„è®ºï¼ˆç”¨äºJSONï¼‰
    all_nested_comments = []
    for note_id, nested_comments in all_comments_data.items():
        all_nested_comments.extend(nested_comments)
    
    # åˆå¹¶æ‰€æœ‰æ‰å¹³è¯„è®ºï¼ˆç”¨äºCSVï¼‰
    all_flat_comments = []
    for note_id, flat_comments in all_comments_flat.items():
        all_flat_comments.extend(flat_comments)
    
    if not all_nested_comments and not all_flat_comments:
        return
    
    # ç¡®ä¿æ•°æ®æ–‡ä»¶ç›®å½•å­˜åœ¨
    ensure_data_file_dir()
    
    # ä¿å­˜JSONï¼ˆåµŒå¥—ç»“æ„ï¼‰
    json_path = DATA_FILE_DIR / 'All CommentData.json'
    with open(json_path, 'w', encoding='utf-8') as f:
        json.dump(all_nested_comments, f, ensure_ascii=False, indent=2)
    
    # ä¿å­˜CSVï¼ˆæ‰å¹³ç»“æ„ï¼ŒæŒ‰æŒ‡å®šåˆ—é¡ºåºï¼‰
    csv_path = DATA_FILE_DIR / 'All CommentData.csv'
    if all_flat_comments:
        with open(csv_path, 'w', newline='', encoding='utf-8') as f:
            writer = csv.DictWriter(f, fieldnames=[
                'content', 'like_count', 'ip_location', 'nickname', 
                'note_id', 'comment_id', 'parent_comment_id', 'is_sub_comment'
            ])
            writer.writeheader()
            writer.writerows(all_flat_comments)
    
    # è®¡ç®—æ‰€æœ‰note_idçš„æ€»è¯„è®ºæ•°
    total_all = sum(len(comments) for comments in all_comments_flat.values())
    # ä½¿ç”¨ rich æ›´æ–°æ˜¾ç¤º
    update_display()


def setup_response_listener(context: BrowserContext):
    """è®¾ç½®å“åº”ç›‘å¬å™¨ï¼Œç›‘å¬è¯„è®ºAPIå“åº”"""
    async def response_handler(response: Response):
        await handle_comment_api_response(response)
    
    context.on('response', response_handler)
    console.print('[green]âœ“[/green] å·²è®¾ç½®è¯„è®ºAPIå“åº”ç›‘å¬å™¨')


async def open_url_in_new_tab(context: BrowserContext, url: str, index: int, total: int):
    """åœ¨æ–°æ ‡ç­¾é¡µæ‰“å¼€URL"""
    try:
        page = await context.new_page()
        
        console.print(f'\n[cyan][{index + 1}/{total}][/cyan] æ‰“å¼€é“¾æ¥: [dim]{url}[/dim]')
        
        # å¯¼èˆªåˆ°URL
        await page.goto(url, wait_until='domcontentloaded', timeout=60000)
        
        # ç­‰å¾…é¡µé¢åŠ è½½
        await page.wait_for_timeout(3000)
        
        # è·å–é¡µé¢æ ‡é¢˜å’Œnote_id
        title = await page.title()
        note_id = extract_note_id_from_url(url)
        
        if not note_id:
            note_id = extract_note_id_from_url(page.url)
        
        console.print(f'  [green]é¡µé¢æ ‡é¢˜:[/green] {title}')
        console.print(f'  [green]note_id:[/green] {note_id}')
        
        # è·å–é¡µé¢æ€»è¯„è®ºæ•°
        total_count = await get_total_comment_count(page)
        if total_count > 0:
            console.print(f'  [green]æ€»è¯„è®ºæ•°:[/green] {total_count}')
        
        # ä¿å­˜note_idå’Œæ ‡é¢˜çš„æ˜ å°„å…³ç³»
        if note_id:
            note_id_to_title[note_id] = title
            note_id_to_page[note_id] = page
            note_id_to_index[note_id] = index + 1  # è®°å½•æ–‡ä»¶åºå·ï¼ˆä»1å¼€å§‹ï¼‰
            if total_count > 0:
                note_id_to_total_count[note_id] = total_count
            processed_note_ids.add(note_id)
            # å¦‚æœå·²ç»æœ‰è¯„è®ºæ•°æ®ï¼Œç«‹å³ä¿å­˜
            if note_id in all_comments_data:
                await save_comments_to_file(note_id)
            # æ›´æ–°æ˜¾ç¤º
            update_display()
        
        return page
        
    except Exception as e:
        console.print(f'  [red]âœ—[/red] æ‰“å¼€é“¾æ¥å¤±è´¥: {str(e)}')
        return None


async def wait_for_login(page: Page):
    """ç­‰å¾…ç”¨æˆ·ç™»å½•"""
    console.print('\n[yellow]ç­‰å¾…ç”¨æˆ·æ‰«ç ç™»å½•å°çº¢ä¹¦...[/yellow]')
    console.print('[dim]è¯·åœ¨æµè§ˆå™¨ä¸­å®Œæˆç™»å½•ï¼Œç™»å½•å®Œæˆåè„šæœ¬ä¼šè‡ªåŠ¨ç»§ç»­[/dim]')
    
    max_wait_time = 300  # æœ€å¤šç­‰å¾…5åˆ†é’Ÿ
    check_interval = 2  # æ¯2ç§’æ£€æŸ¥ä¸€æ¬¡
    elapsed_time = 0
    
    while elapsed_time < max_wait_time:
        try:
            # æ£€æŸ¥æ˜¯å¦å·²ç™»å½•ï¼ˆé€šè¿‡æ£€æŸ¥é¡µé¢å†…å®¹ï¼‰
            is_logged_in = await page.evaluate("""
                () => {
                    const text = document.body.innerText || '';
                    return !text.includes('ç™»å½•') && 
                           !text.includes('ç«‹å³ç™»å½•') && 
                           !text.includes('è¯·ç™»å½•') &&
                           !text.includes('æ‰«ç ç™»å½•');
                }
            """)
            
            if is_logged_in:
                console.print('[green]âœ“[/green] æ£€æµ‹åˆ°å·²ç™»å½•ï¼Œç»§ç»­æ‰§è¡Œ...')
                await page.wait_for_timeout(2000)
                return True
            
            await asyncio.sleep(check_interval)
            elapsed_time += check_interval
            
            if elapsed_time % 10 == 0:
                console.print(f'  [dim]ç­‰å¾…ä¸­... ({elapsed_time}/{max_wait_time}ç§’)[/dim]')
                
        except Exception as e:
            console.print(f'  [yellow]æ£€æŸ¥ç™»å½•çŠ¶æ€æ—¶å‡ºé”™: {str(e)}[/yellow]')
            await asyncio.sleep(check_interval)
            elapsed_time += check_interval
    
    console.print('[yellow]âš [/yellow] ç­‰å¾…ç™»å½•è¶…æ—¶ï¼Œç»§ç»­æ‰§è¡Œ...')
    return False


async def main():
    """ä¸»å‡½æ•°"""
    # è¯»å–URLåˆ—è¡¨
    urls = []
    
    # ä¼˜å…ˆä»å˜é‡åˆ—è¡¨è¯»å–
    if URL_LIST:
        urls.extend(URL_LIST)
        console.print(f'[green]âœ“[/green] ä»å˜é‡åˆ—è¡¨è¯»å–åˆ° [cyan]{len(URL_LIST)}[/cyan] ä¸ªURL')
    
    # ä»Excelæ–‡ä»¶è¯»å–
    excel_urls = read_urls_from_excel(EXCEL_FILE)
    urls.extend(excel_urls)
    
    # å»é‡
    urls = list(dict.fromkeys(urls))  # ä¿æŒé¡ºåºçš„å»é‡
    
    if not urls:
        console.print('[red]é”™è¯¯ï¼šæœªæ‰¾åˆ°ä»»ä½•URLï¼Œè¯·åœ¨URL_LISTå˜é‡ä¸­å¡«å…¥é“¾æ¥æˆ–ç¡®ä¿Excelæ–‡ä»¶å­˜åœ¨ä¸”åŒ…å«URL[/red]')
        return
    
    console.print(f'\n[bold cyan]æ€»å…±éœ€è¦å¤„ç†çš„URLæ•°é‡: {len(urls)}[/bold cyan]')
    
    user_data_dir = get_user_data_dir()
    
    console.print('\n[bold blue]å¯åŠ¨æµè§ˆå™¨ï¼ˆä½¿ç”¨æŒä¹…åŒ–ä¸Šä¸‹æ–‡ï¼Œç™»å½•çŠ¶æ€ä¼šè¢«ä¿å­˜ï¼‰...[/bold blue]')
    console.print(f'[dim]ç”¨æˆ·æ•°æ®ç›®å½•: {user_data_dir}[/dim]')
    
    async with async_playwright() as p:
        # ä½¿ç”¨ launch_persistent_context åˆ›å»ºæŒä¹…åŒ–ä¸Šä¸‹æ–‡
        context = await p.chromium.launch_persistent_context(
            user_data_dir,
            headless=False,  # æ˜¾ç¤ºæµè§ˆå™¨çª—å£
            channel='chrome',  # ä½¿ç”¨ç³»ç»Ÿå®‰è£…çš„ Chrome
            args=[
                '--disable-blink-features=AutomationControlled',  # éšè—è‡ªåŠ¨åŒ–ç‰¹å¾
            ],
        )
        
        # è®¾ç½®é¡µé¢é»˜è®¤ç¼©æ”¾ä¸º80%
        await context.add_init_script("""
            (function() {
                function setZoom() {
                    if (document.body) {
                        document.body.style.zoom = '0.8';
                    }
                    if (document.documentElement) {
                        document.documentElement.style.zoom = '0.8';
                    }
                }
                // ç«‹å³è®¾ç½®
                setZoom();
                // ç›‘å¬ DOM å˜åŒ–ï¼Œç¡®ä¿ç¼©æ”¾ç”Ÿæ•ˆ
                const observer = new MutationObserver(setZoom);
                if (document.body) {
                    observer.observe(document.body, { attributes: true, attributeFilter: ['style'] });
                }
                observer.observe(document.documentElement, { 
                    childList: true, 
                    subtree: true,
                    attributes: true,
                    attributeFilter: ['style']
                });
                // é¡µé¢åŠ è½½å®Œæˆåå†æ¬¡è®¾ç½®
                if (document.readyState === 'complete' || document.readyState === 'interactive') {
                    setZoom();
                } else {
                    window.addEventListener('load', setZoom);
                    document.addEventListener('DOMContentLoaded', setZoom);
                }
            })();
        """)
        
        try:
            # è®¾ç½®å“åº”ç›‘å¬å™¨
            setup_response_listener(context)
            
            # æ‰“å¼€å°çº¢ä¹¦é¦–é¡µ
            console.print('\n[bold blue]æ‰“å¼€å°çº¢ä¹¦é¦–é¡µ...[/bold blue]')
            home_page = await context.new_page()
            await home_page.goto('https://www.xiaohongshu.com/', wait_until='domcontentloaded', timeout=60000)
            await home_page.wait_for_timeout(3000)
            
            # ç­‰å¾…ç”¨æˆ·ç™»å½•
            await wait_for_login(home_page)
            
            console.print('\n[bold blue]å¼€å§‹æ‰“å¼€è§†é¢‘é“¾æ¥...[/bold blue]')
            pages = []
            
            # åœ¨æ–°æ ‡ç­¾é¡µæ‰“å¼€æ¯ä¸ªURL
            for i, url in enumerate(urls):
                page = await open_url_in_new_tab(context, url, i, len(urls))
                if page:
                    pages.append(page)
                    # è®°å½•note_idå’Œæ–‡ä»¶åºå·çš„æ˜ å°„ï¼ˆä»1å¼€å§‹ï¼‰
                    note_id = extract_note_id_from_url(url)
                    if not note_id:
                        note_id = extract_note_id_from_url(page.url)
                    if note_id and note_id not in note_id_to_index:
                        note_id_to_index[note_id] = i + 1
                
                # å¦‚æœä¸æ˜¯æœ€åä¸€ä¸ªï¼Œç­‰å¾…ä¸€ä¸‹
                if i < len(urls) - 1:
                    await asyncio.sleep(2)
            
            console.print(f'\n[bold green]âœ“[/bold green] å·²æ‰“å¼€ [bold cyan]{len(pages)}[/bold cyan] ä¸ªæ ‡ç­¾é¡µ')
            console.print('\n[bold yellow]å¼€å§‹ç›‘å¬è¯„è®ºAPIè¯·æ±‚...[/bold yellow]')
            console.print('[dim]è„šæœ¬å°†æŒç»­è¿è¡Œï¼Œç›‘å¬è¯„è®ºæ•°æ®[/dim]')
            console.print('[dim]å½“ç”¨æˆ·åœ¨æµè§ˆå™¨ä¸­ç¿»é¡µæŸ¥çœ‹è¯„è®ºæ—¶ï¼Œæ•°æ®ä¼šè‡ªåŠ¨ä¿å­˜[/dim]')
            console.print('[dim]æŒ‰Ctrl+Cåœæ­¢è„šæœ¬è¿è¡Œ[/dim]\n')
            
            # ä½¿ç”¨ Live å®æ—¶æ›´æ–°æ˜¾ç¤º
            global live_display
            with Live(create_status_panel(), refresh_per_second=2, screen=False) as live:
                live_display = live
                
                # æŒç»­è¿è¡Œï¼Œç›´åˆ°ç”¨æˆ·ä¸­æ–­
                try:
                    check_count = 0
                    while True:
                        await asyncio.sleep(2)  # æ›´é¢‘ç¹åœ°æ›´æ–°æ˜¾ç¤º
                        # å®šæœŸä¿å­˜æ•°æ®
                        if all_comments_data:
                            await save_all_comments_to_file()
                        
                        # æ¯10æ¬¡å¾ªç¯ï¼ˆçº¦20ç§’ï¼‰æ£€æŸ¥ä¸€æ¬¡æ€»è¯„è®ºæ•°
                        check_count += 1
                        if check_count >= 10:
                            check_count = 0
                            # å°è¯•æ›´æ–°æ€»è¯„è®ºæ•°
                            for note_id, page in note_id_to_page.items():
                                if note_id not in note_id_to_total_count or note_id_to_total_count[note_id] == 0:
                                    try:
                                        if not page.is_closed():
                                            total_count = await get_total_comment_count(page)
                                            if total_count > 0:
                                                note_id_to_total_count[note_id] = total_count
                                    except:
                                        pass
                        
                        # æ›´æ–°æ˜¾ç¤º
                        update_display()
                except (KeyboardInterrupt, asyncio.CancelledError):
                    console.print('\n\n[yellow]ç”¨æˆ·ä¸­æ–­ç¨‹åºï¼Œæ­£åœ¨ä¿å­˜æ•°æ®...[/yellow]')
                finally:
                    live_display = None
            
            # ä¿å­˜æœ€ç»ˆæ•°æ®
            if all_comments_data:
                console.print('\n[yellow]ä¿å­˜æœ€ç»ˆæ•°æ®...[/yellow]')
                try:
                    for note_id in all_comments_data.keys():
                        await save_comments_to_file(note_id)
                    await save_all_comments_to_file()
                    
                    total_comments = sum(len(comments) for comments in all_comments_flat.values())
                    console.print(f'\n[bold green]âœ“[/bold green] æ•°æ®ä¿å­˜å®Œæˆï¼')
                    console.print(f'  [cyan]å…±å¤„ç† {len(all_comments_data)} ä¸ªnote_id[/cyan]')
                    console.print(f'  [cyan]å…±æŠ“å– {total_comments} æ¡è¯„è®º[/cyan]')
                    console.print(f'  [dim]æ•°æ®å·²ä¿å­˜åˆ°å¯¹åº”çš„JSONå’ŒCSVæ–‡ä»¶ä¸­[/dim]')
                except Exception:
                    pass  # é™é»˜å¤„ç†ä¿å­˜æ•°æ®æ—¶çš„å¼‚å¸¸
            else:
                console.print('\n[yellow]âš [/yellow] æœªæŠ“å–åˆ°ä»»ä½•è¯„è®ºæ•°æ®')
            
        except (KeyboardInterrupt, asyncio.CancelledError):
            # ç”¨æˆ·ä¸­æ–­ï¼Œä¸æ˜¾ç¤ºé”™è¯¯ä¿¡æ¯
            pass
        except Exception as err:
            # å…¶ä»–å¼‚å¸¸æ‰æ˜¾ç¤ºé”™è¯¯ä¿¡æ¯
            console.print(f'\n[red]è¿è¡Œå‡ºé”™ï¼š{err}[/red]')
            import traceback
            traceback.print_exc()
        finally:
            # ä¼˜é›…å…³é—­æµè§ˆå™¨ï¼Œæ•è·æ‰€æœ‰å¯èƒ½çš„å¼‚å¸¸
            try:
                await context.close()
            except Exception:
                # é™é»˜å¤„ç†å…³é—­æµè§ˆå™¨æ—¶çš„å¼‚å¸¸ï¼ˆå¦‚è¿æ¥å·²å…³é—­ï¼‰
                pass
            console.print('\n\n[dim]å·²å…³é—­æµè§ˆå™¨...[/dim]\n')


if __name__ == '__main__':
    try:
        asyncio.run(main())
    except (KeyboardInterrupt, asyncio.CancelledError):
        # ç”¨æˆ·ä¸­æ–­ï¼Œä¸æ˜¾ç¤ºé”™è¯¯ä¿¡æ¯
        console.print('\n[dim]å·²å…³é—­æµè§ˆå™¨[/dim]')
        exit(0)
    except Exception as err:
        # å…¶ä»–å¼‚å¸¸æ‰æ˜¾ç¤ºé”™è¯¯ä¿¡æ¯
        console.print(f'[red]è¿è¡Œå‡ºé”™ï¼š{err}[/red]')
        import traceback
        traceback.print_exc()
        exit(1)

